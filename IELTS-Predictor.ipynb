{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook includes the source code prepared for COMP5393-Capstone Project.\n",
    "Project Title: Automated IELTS Essay Scoring by Using Machine Learning Algorithms\n",
    "Project Author: Ekrem Bakay\n",
    "Project Advisor: Dr. Mustafa Duran\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IELTS Predictor\n",
    "\n",
    "IELTS is an international assessment tool which tests the ability to listen, read, write and speak in English and is graded on a scale of 1-9. While preparing to the exam, students usually take practice exams in which they can master their language skills. Unlike the IELTS reading and listening part, evaluating the IELTS writing task is time-consuming and also it needs an expert teacher which costs lots of money. With Artificial Intelligence, Machine Learning and Natural Language Processing it is now possible to get instant IELTS writing evaluation. This project will automate the evaluation and scoring of an IELTS practice essay by using machine learning models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1-Importing Necessary Libraries\n",
    "In the first step, I always import all the necessary python libraries in the first cell. Below cell imports all the libraries used in this notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's set the seed of the random number generator to a fixed value, so that when it is called, the results will be reproducible."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______\n",
    "______"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2- Data Preparation\n",
    "### 2.1- Creating the Dataseet\n",
    "After finding 204 pdf documents which provides three different rater scores for various task 2 essay texts, I converted each pdf to a txt file which includes essay topic, essay body and three scores separated by # sign. Each txt file was then processed and collected as a dataset by a python code and saved as csv file which will be used in further steps. Below cells include the python code which converts txt file to pandas dataframe and saves it as csv."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# function to convert each txt file to a dictionary object\n",
    "def load_files():\n",
    "    new_dic = {}\n",
    "    Topic, Essay, S1, S2, S3 = [], [] , [], [], []\n",
    "    file_path = os.path.join(os.getcwd(), \"essays/\")\n",
    "    for file in os.listdir(file_path):\n",
    "        extension = os.path.splitext(file)[1]\n",
    "        if extension == \".txt\":\n",
    "            with open(os.path.join(file_path, file)) as f:\n",
    "                index = 0\n",
    "                essay_line = \"\"\n",
    "                for line in f:\n",
    "                    if line.strip()=='#':\n",
    "                        index += 1\n",
    "                        continue\n",
    "                    if index == 0:\n",
    "                        Topic.append(line.strip())\n",
    "                    elif index == 1:\n",
    "                        essay_line = essay_line + \" \" + line.strip()\n",
    "                    elif index == 2:\n",
    "                        S1.append(float(line.rstrip()))\n",
    "                    elif index == 3:\n",
    "                        S2.append(float(line.rstrip()))\n",
    "                    else:\n",
    "                        S3.append(float(line.rstrip()))\n",
    "                Essay.append(essay_line)\n",
    "        new_dic = {'EssayTopic': Topic, 'EssayBody': Essay, 'S1': S1, 'S2': S2, 'S3': S3}\n",
    "    return new_dic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# use load_files function to get the txt file content as dictionary object and convert it to pandas dataframe\n",
    "df = pd.DataFrame.from_dict(load_files())\n",
    "\n",
    "# calculate average essay score by combining three rater scores\n",
    "df['EssayScore'] = np.round(((df[\"S1\"] + df[\"S2\"] + df[\"S3\"])/3)*2)/2\n",
    "\n",
    "# save the dataframe as csv file to be used in further processing\n",
    "df.to_csv(\"essay_dataset.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Importing data\n",
    "In the next step, created csv file is imported to be used in the remaining of this notebook. Pandas libraries will be used to import the csv data and process it as a dataframe named 'essays'. After importing, values are sorted according to 'EssayScore' column which hold the target essay score. Below cell executes the code for import process, and output shows a part of the dataframe created."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           EssayTopic  \\\n60  What kind of climate do you prefer to live in?...   \n55  What kind of climate do you prefer to live in?...   \n31  It is possible to be single for all your life ...   \n40  Money can solve all problems. Do you agree or ...   \n10  What kind of climate do you prefer to live in?...   \n\n                                            EssayBody   S1   S2   S3  \\\n60   Human live in the earth, as result they have ...  5.0  5.5  5.0   \n55   If I want to choose a climate for living in t...  5.0  5.0  5.0   \n31   As long as the world around us has become mod...  5.0  5.0  5.0   \n40   These days, people’s life is more complex, ha...  5.0  5.0  5.0   \n10   If I want to choose a climate for living in t...  5.0  5.0  5.0   \n\n    EssayScore  \n60         5.0  \n55         5.0  \n31         5.0  \n40         5.0  \n10         5.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EssayTopic</th>\n      <th>EssayBody</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>EssayScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>Human live in the earth, as result they have ...</td>\n      <td>5.0</td>\n      <td>5.5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>If I want to choose a climate for living in t...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>It is possible to be single for all your life ...</td>\n      <td>As long as the world around us has become mod...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Money can solve all problems. Do you agree or ...</td>\n      <td>These days, people’s life is more complex, ha...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>If I want to choose a climate for living in t...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays = pd.read_csv('essay_dataset.csv')\n",
    "essays.sort_values(by=['EssayScore'], inplace=True)\n",
    "essays.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Exploratory Data Analysis\n",
    "Let's check the data type for each column and whether there is any missing data. As it can be seen from the output, EssayTopic and EssayBody columns have the \"object\" type and all the other column have \"float\" data type. None of the columns has missing value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EssayTopic     object\n",
      "EssayBody      object\n",
      "S1            float64\n",
      "S2            float64\n",
      "S3            float64\n",
      "EssayScore    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "EssayTopic    0\n",
      "EssayBody     0\n",
      "S1            0\n",
      "S2            0\n",
      "S3            0\n",
      "EssayScore    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print data types and number of null values for each column\n",
    "print(essays.dtypes)\n",
    "print('\\n')\n",
    "print(essays.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pandas’s describe function gives an overview about numeric features of the data which is presented in the below table. According to table, the data contains 68 rows of values. The minimum value for essay scores is five, while the maximum value is nine."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d4bff8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              S1         S2         S3  EssayScore\ncount  68.000000  68.000000  68.000000   68.000000\nmean    7.470588   7.551471   7.477941    7.522059\nstd     1.218276   1.149756   1.107754    1.144206\nmin     5.000000   5.000000   5.000000    5.000000\n25%     6.500000   6.500000   6.875000    6.500000\n50%     8.000000   8.000000   8.000000    8.000000\n75%     8.500000   8.500000   8.500000    8.500000\nmax     9.000000   9.000000   9.000000    9.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>EssayScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>68.000000</td>\n      <td>68.000000</td>\n      <td>68.000000</td>\n      <td>68.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7.470588</td>\n      <td>7.551471</td>\n      <td>7.477941</td>\n      <td>7.522059</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.218276</td>\n      <td>1.149756</td>\n      <td>1.107754</td>\n      <td>1.144206</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.500000</td>\n      <td>6.500000</td>\n      <td>6.875000</td>\n      <td>6.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.500000</td>\n      <td>8.500000</td>\n      <td>8.500000</td>\n      <td>8.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>9.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the statistics for numeric columns\n",
    "essays.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although IELTS band scores are between 1 and 9, our dataset includes scores from 5 till 9 incremented by 0.5. Below chart shows the distribution of unique scores according to their number of occurrences in the dataset. Each score occurs in the following frequencies; 5: 5 times, 5.5: 1 time, 6: 4 times, 6.5: 8 times, 7: 6 times, 7.5: 7 times, 8: 14 times, 8.5: 17 times, 9: 6 times.\n",
    "\n",
    "As it can be seen from the above chart that the data distribution is unbalanced. Thus, it should be organized in way that it will produce results without bias. In order to reduce to complexity of the analysis and provide balance for the dataset, the closer scores will be grouped under three main classes such that; low band: scores between 5 and 6.5, moderate band: scores between 7 and 8, and high band: scores above 8."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b0f6a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the unique value counts for the EssayScore column which holds the target data.\n",
    "essays['EssayScore'].value_counts().sort_index().plot(kind='bar', figsize=(10,8), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another property that is going to be explored is the sequence length, i.e. word count, in each essay. Later in data preprocessing step, it will be used to determine the maximum length for data tokenization. Below chart shows the frequency of the word counts for all the essay data. The yellow line represents the mean value of the word counts which is almost 300 words in average."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07d4ed0-81ab-450b-8d3c-292d131b1e1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the word counts in each essay body.\n",
    "seqlen = essays['EssayBody'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d32648-b913-47d0-87b6-3a20837aadf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.lines.Line2D at 0x7fc1286b3370>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 604.8x504 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the word count frequencies for each word count range\n",
    "sns.set_style('darkgrid')\n",
    "sns.displot(seqlen, height=7, aspect=1.2)\n",
    "plt.axvline(x=seqlen.mean(), linewidth=3, color='y', label=\"mean\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4-Data Preprocessing\n",
    "#### 2.4.1 Encoding Score Data\n",
    "In order to simplify data processing and improve the classification accuracy, the target data (essay scores) need to be grouped according to the score range. Below cell includes a function that checks for each essay and replaces the score value accordingly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# function to relabel essay score data\n",
    "def new_label(value):\n",
    "    if value > 8:\n",
    "        return 'High Band'\n",
    "    elif value > 7:\n",
    "        return 'Moderate Band'\n",
    "    else:\n",
    "        return 'Low Band'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's apply above function to EssayScore column to change the label values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           EssayTopic  \\\n60  What kind of climate do you prefer to live in?...   \n55  What kind of climate do you prefer to live in?...   \n31  It is possible to be single for all your life ...   \n40  Money can solve all problems. Do you agree or ...   \n10  What kind of climate do you prefer to live in?...   \n\n                                            EssayBody   S1   S2   S3  \\\n60   Human live in the earth, as result they have ...  5.0  5.5  5.0   \n55   If I want to choose a climate for living in t...  5.0  5.0  5.0   \n31   As long as the world around us has become mod...  5.0  5.0  5.0   \n40   These days, people’s life is more complex, ha...  5.0  5.0  5.0   \n10   If I want to choose a climate for living in t...  5.0  5.0  5.0   \n\n   EssayScore  \n60   Low Band  \n55   Low Band  \n31   Low Band  \n40   Low Band  \n10   Low Band  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EssayTopic</th>\n      <th>EssayBody</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>EssayScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>Human live in the earth, as result they have ...</td>\n      <td>5.0</td>\n      <td>5.5</td>\n      <td>5.0</td>\n      <td>Low Band</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>If I want to choose a climate for living in t...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>Low Band</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>It is possible to be single for all your life ...</td>\n      <td>As long as the world around us has become mod...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>Low Band</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Money can solve all problems. Do you agree or ...</td>\n      <td>These days, people’s life is more complex, ha...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>Low Band</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>What kind of climate do you prefer to live in?...</td>\n      <td>If I want to choose a climate for living in t...</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>Low Band</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply new_label function\n",
    "essays['EssayScore'] = essays['EssayScore'].map(new_label)\n",
    "essays.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After executing the code, distribution of the new scores values and their frequencies will be printed by using the below code and chart."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Band         24\n",
      "High Band        23\n",
      "Moderate Band    21\n",
      "Name: EssayScore, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAINCAYAAADIlfA3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcVklEQVR4nO3df5DXdYHH8deyyyK6EKhbYSSiUgbOTr/UmlFn6iQslbDJa6GhKTjr0iwm+6FoaFpi12E2jMhk/lGpQ9R1N1yaXtLccQ1NenepqUP4C0PzR06tsgrL7vK9P0737IfwFr/L57vffTxmmmF3wX0N8x57+vl8v59tqdVqtQAAsEdjqh4AADBSCCcAgELCCQCgkHACACgknAAACgknAIBCbbv7Yn9/f5YuXZpHH300O3fuzCc/+clMmTIln/jEJ3LYYYclSebPn5/3ve99u/0mu3btyuCgpx7sS62tLf7OaXrOOaOBc77vjR3b+pJfa9ndc5z+6Z/+KZs2bcoFF1yQnp6ezJs3L2effXa2bduWRYsWFQ/o7x9MT89zL281r8ikSfv7O6fpOeeMBs75vtfZOeElv7bbK04nn3xy5syZkySp1WppbW3N3XffnYceeijr16/PtGnTsnTp0nR0dNR3MQBAA9rta5wOOOCAdHR0pLe3N5/+9KezZMmSdHV15Qtf+EKuv/76vP71r89VV121r7YCAFRqt1eckuSxxx7L2WefnQULFuS0007LM888k4kTJyZJZs+enUsvvXSP36S1tSWTJu3/ytdSrLV1jL9zmp5zzmjgnDeW3YbTU089lUWLFmXZsmV55zvfmSRZvHhxvvSlL6Wrqyu/+MUvMmvWrD1+k8HBmvuz+5h74owGzjmjgXO+7+31a5xWr16dZ555JqtWrcqqVauSJOedd14uu+yyjB07NgcffHDRFScAgGaw23fV1Yt31e17/guF0cA5ZzRwzve93V1x8gBMAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCbVUPaHQdE8dn/LiR+de0u5/u3Mi29w2k95ntVc8AgL8wMotgHxo/ri2HnXdj1TNGlS2Xn5LeqkcAwF/hVh0AQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABRqq3oAUL2OieMzftzI/NdBZ+eEqifsle19A+l9ZnvVM4CXaWT+mxKoq/Hj2nLYeTdWPWNU2XL5KemtegTwsrlVBwBQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFCoreoBALAvdEwcn/HjRub/7XV2Tqh6wl7Z3jeQ3me2Vz2jrkbmCQKAl2n8uLYcdt6NVc8YVbZcfkp6qx5RZ27VAQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAECh3f6suv7+/ixdujSPPvpodu7cmU9+8pM58sgjc95556WlpSUzZszIRRddlDFj9BcA0Px2G07r1q3LpEmT8vWvfz09PT2ZN29ejjrqqCxZsiTHHXdcli1blvXr12f27Nn7ai8AQGV2e6no5JNPzmc+85kkSa1WS2tra+65554ce+yxSZITTzwxGzduHP6VAAANYLfhdMABB6SjoyO9vb359Kc/nSVLlqRWq6WlpWXo69u2bdsnQwEAqrbbW3VJ8thjj+Xss8/OggULctppp+XrX//60NeeffbZTJw4cY/fpLW1JZMm7f/KljKqOC+MBs45o0GznfPdhtNTTz2VRYsWZdmyZXnnO9+ZJJk5c2Z++ctf5rjjjsuGDRvyjne8Y4/fZHCwlp6e5+qzeB/r7JxQ9YRRaaSel5HKOa+Gc75vOefVGInnfHdnZbe36lavXp1nnnkmq1atysKFC7Nw4cIsWbIkK1euzIc+9KH09/dnzpw5dR8MANCIdnvF6cILL8yFF174F5+/7rrrhm0QAECj8gAmAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKFQUTnfeeWcWLlyYJLn33ntzwgknZOHChVm4cGFuuummYR0IANAo2vb0G6655pqsW7cu48ePT5Lcc889+djHPpZFixYN+zgAgEayxytOhx56aFauXDn08d13351///d/z4c//OEsXbo0vb29wzoQAKBR7PGK05w5c/LII48MfdzV1ZUzzjgjRx99dK6++upcddVV+eIXv7jbf0Zra0smTdr/la9l1HBeGA2cc0aDZjvnewynPzd79uxMnDhx6NeXXnrpHv/M4GAtPT3Pvfx1DaCzc0LVE0alkXpeRirnvBrO+b7lnFdjJJ7z3Z2Vl/2uusWLF+euu+5KkvziF7/IrFmz9n4ZAMAI8rKvOF188cW59NJLM3bs2Bx88MFFV5wAAJpBUThNnTo1a9euTZLMmjUra9asGdZRAACNyAMwAQAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCwgkAoJBwAgAoJJwAAAoJJwCAQsIJAKCQcAIAKCScAAAKCScAgELCCQCgkHACACgknAAACgknAIBCReF05513ZuHChUmShx9+OPPnz8+CBQty0UUXZdeuXcM6EACgUewxnK655ppceOGF6evrS5IsX748S5YsyQ033JBarZb169cP+0gAgEawx3A69NBDs3LlyqGP77nnnhx77LFJkhNPPDEbN24cvnUAAA2kbU+/Yc6cOXnkkUeGPq7VamlpaUmSHHDAAdm2bdsev0lra0smTdr/FcxktHFeGA2cc0aDZjvnewynPzdmzP9fpHr22WczceLEPf6ZwcFaenqee7nfqiF0dk6oesKoNFLPy0jlnFfDOd+3nPNqjMRzvruz8rLfVTdz5sz88pe/TJJs2LAhb3/72/d+GQDACPKyw+mLX/xiVq5cmQ996EPp7+/PnDlzhmMXAEDDKbpVN3Xq1KxduzZJMn369Fx33XXDOgoAoBF5ACYAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUKhtb//g6aefno6OjiTJ1KlTs3z58rqNAgBoRHsVTn19fanVavne975X7z0AAA1rr27Vbdq0Kdu3b8+iRYvykY98JHfccUedZwEANJ69uuK03377ZfHixTnjjDOyZcuWnHnmmbn55pvT1rbXd/4AABreXpXO9OnTM23atLS0tGT69OmZNGlSfv/732fKlCl/9fe3trZk0qT9X9FQRhfnhdHAOWc0aLZzvlfh9MMf/jCbN2/OxRdfnCeeeCK9vb3p7Ox8yd8/OFhLT89zez2ySp2dE6qeMCqN1PMyUjnn1XDO9y3nvBoj8Zzv7qzsVTh98IMfzPnnn5/58+enpaUll112mdt0AEDT26vaaW9vz4oVK+q9BQCgoXkAJgBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABQSTgAAhYQTAEAh4QQAUEg4AQAUEk4AAIWEEwBAIeEEAFBIOAEAFBJOAACFhBMAQCHhBABQSDgBABRq25s/tGvXrlx88cX5zW9+k/b29nzlK1/JtGnT6r0NAKCh7NUVp1tvvTU7d+7M97///Zx77rm5/PLL670LAKDh7FU4/fd//3dOOOGEJMmb3/zm3H333XUdBQDQiPbqVl1vb286OjqGPm5tbc3AwEDa2v76P27s2NZ0dk7Yu4UNYMvlp1Q9YdQZyedlpHLO9z3nfN9zzve9Zjvne3XFqaOjI88+++zQx7t27XrJaAIAaBZ7FU5vfetbs2HDhiTJHXfckTe84Q11HQUA0IhaarVa7eX+oRfeVbd58+bUarVcdtllOeKII4ZjHwBAw9ircAIAGI08ABMAoJBwAgAoJJwAAAoJJwCAQh6+1ATe/e53p6WlZejjtra2DAwMpL29PT/5yU8qXAb1c/zxxydJ+vv7s3379kyZMiWPP/54DjrooPzsZz+reB3Uh3Pe+IRTE7j55ptTq9Xy5S9/Od3d3enq6sq9996bG264oeppUDc///nPkySf+9zncu6552bKlCl54oknsnz58oqXQf04541PODWB9vb2JMnWrVvT1dWVJJk5c2YeeuihKmfBsHjkkUcyZcqUJMlrXvOaPPbYYxUvgvpzzhuXcGoiEyZMyJVXXpmurq786le/SmdnZ9WToO6OOOKIfP7znx8657Nmzap6EtSdc964PACziTz33HNZs2ZNtmzZkiOPPDLd3d1DV6OgWezatSs//elPs2XLlhxxxBE56aSTqp4EdeecNy7h1ERqtVp+/etfp6+vb+hzxxxzTIWLoP56e3uzYcOG7Ny5c+hz8+bNq24QDAPnvHG5VddEzjnnnPzhD3/IlClTUqvV0tLSIpxoOmeddVZe/epXD73+48XvKIVm4Zw3LuHURJ566qmsWbOm6hkwrGq1Wv7xH/+x6hkwrJzzxuUBmE1k+vTpeeKJJ6qeAcPqjW98Y+68887s3Llz6H/QbJzzxuU1Tk1kzpw52bp1aw488MChz73wTBBoFnPnzk1vb+/Qxy0tLVm/fn2Fi6D+nPPGJZwAAAp5jVMTueOOO/KjH/0o/f39SZInn3wy1157bcWroL7Wr1+fG264If39/anVaunp6cm//uu/Vj0L6so5b1xe49RELr744hx77LHp7e3NIYcckkmTJlU9CeruyiuvzKc+9alMmTIlp59+et7whjdUPQnqzjlvXMKpiUyePDmnnnpqOjo6cs4553ihOE3p1a9+dd7ylrckST7wgQ/kySefrHgR1J9z3riEUxMZM2ZM7rvvvmzfvj0PPvhgnn766aonQd2NHTs2t99+ewYGBvKf//mf+eMf/1j1JKg757xxeXF4E7nvvvty33335TWveU2++tWvZu7cufnoRz9a9SyoqyeeeCIPPvhgOjs7881vfjMnn3xyTjnllKpnQV05541LODWhxx57LAMDA3n9619f9RQYNv/zP/+T/v7+HHfccVVPgWHjnDce76prAhs3bszy5ctz0EEHZe7cubniiisyfvz4/O3f/m3OPPPMqudBXaxbty5f+9rX8qpXvSrve9/7csstt2TixIk5+uijc/7551c9D+rCOW98wqkJXHHFFVm5cmWefvrpfPSjH82tt96aCRMmZOHChcKJpvGd73wnt9xyS7Zt25Z58+blZz/7Wfbff//Mnz+/6mlQN8554xNOTWD8+PE57LDDkiRvetObctBBByVJ9ttvvwpXQX3tv//+6ejoSEdHR2bMmJEDDjggSdLe3l7xMqgf57zxeVddE3jxT81ua/v/FvbyNZrJi8/5mDH+1UVzcs4bnxeHN4G3ve1tmTFjRmq1Wu6///6hXz/wwAP5r//6r6rnQV0cffTRQw917enpGfr1008/nV//+tfVDYM6cs4bn3BqAo8++uhLfu11r3vdPlwCAM1NOAEAFHIDFQCgkHBqIn6WEUBz6enpqXoCf8atuiayePHi7Ny5M+9617sye/ZsTw6nKa1duzbf+c53smPHjtRqtbS0tGT9+vVVz4K6uu2223LJJZdkcHAwJ598cg455JCcccYZVc8iwqnp9Pb2ZsOGDfnud7+bHTt25F/+5V+qngR19YEPfCArV65MZ2fn0Oc844Zm8+EPfzhXXXVVzjnnnHz729/O/Pnz86Mf/ajqWcQDMJvKrbfemo0bN+bOO+/MIYcckuOPP77qSVB3kydP9m5Rmt6YMWMyadKktLS0ZNy4cUMPwqR6wqmJrFixIu3t7fn4xz+eE044IRMnTqx6EtTNFVdckSTZuXNnFi9enJkzZw49LPCzn/1sldOg7g499NCsWLEiPT09+da3vpVDDjmk6kk8z626JvPII4/k5z//eW666abs2LEja9eurXoS1MU///M/v+TXTj/99H24BIbfwMBAfvCDH2Tz5s05/PDD093dnbFjx1Y9iwinpnLPPffkP/7jP7Jx48bst99++Zu/+Rs/GJKm8+ev22tra8trX/vavP3tb69mEAyDSy65JMuWLRv6+Atf+EL+4R/+ocJFvMCtuiZy9dVXZ/bs2bn66qszYcKEqufAsLjxxhuzY8eOvPnNb85dd92Vvr6+tLa2ZtasWVm6dGnV8+AVuf7663P11Venp6cn//Zv/zb0+SOOOKLCVbyYK05NZNu2bVm1alUeeOCBHHbYYTnrrLOGfs4RNIuPfexjufbaazNmzJjs2rUrZ555Zq699tp0d3dnzZo1Vc+Duli9enX+/u//vuoZ/BWuODWRCy64IMccc0zmzp2b2267Leedd15Wr15d9Syoq56engwMDKS9vT0DAwN5+umnk/zfi8ahWXR3d+fHP/5xBgYGUqvV8uSTT+YTn/hE1bOIcGoqf/zjH7Nw4cIkyZve9KbccsstFS+C+luwYEFOO+20zJgxIw8++GD+7u/+LqtXr84JJ5xQ9TSom0996lM5/PDDs3nz5owbNy7jx4+vehLPE05NpK+vL7///e/T2dmZp556Krt27ap6EtTdGWeckZNOOim//e1vc+ihh2by5MkZHBxMa2tr1dOgbmq1Wi655JKcf/75+epXv5oFCxZUPYnnCacm8pnPfCbd3d2ZMGFCent7c+mll1Y9Cepm1apVOeuss/LZz3526PlNL1ixYkVFq2B4tLa2pq+vL9u3b09LS0sGBwernsTzvDi8Cf3hD3/IgQcemIcffjjTpk2reg7UxaZNm3LUUUfltttu+4uvHXvssRUsguFzyy235OGHH87kyZOzcuXKvO1tb8s3vvGNqmcRV5ya0oEHHpgkOffcc/PDH/6w4jVQH5s2bcqmTZuqngH7RF9fXz7+8Y8nSd773vemo6Oj4kW8QDg1MRcTaSYPPPDA0K9vvPHGnHrqqanVan9x2w6awdq1azN37twkEU0NRjg1Mf+HQjM599xzh359xx13+Pl0NLWdO3dm3rx5mT59esaMGZPEa/kahXBqAn/txbK1Wi1bt26taBEML/9RQLP73Oc+V/UEXoJwagLd3d0v6/MANLaZM2fmmmuuyZNPPpl3vetdeeMb31j1JJ4nnJqAdxQxGrxwZbVWq+X+++//k1t3bmHQbJYuXZoTTzwxt99+ew4++OBccMEFue6666qeRYQTMEK8+Aqqq6k0u56ennzwgx/MunXr8ta3vtUDjRuIcAJGBFdWGW1eeCfp448/7sn4DcQDMAGgwfzmN7/JsmXL8sADD+Twww/PRRddlFmzZlU9iwgnAIBibtUBQIN497vf/SeP22hra8vAwEDa29vzk5/8pMJlvEA4AUCDuPnmm1Or1fLlL3853d3d6erqyr333psbbrih6mk8TzgBQINob29PkmzdujVdXV1J/u+ZTg899FCVs3gR4QQADWbChAm58sor09XVlV/96lfp7OysehLP8+JwAGgwzz33XNasWZMtW7bkyCOPTHd399DVKKo1puoBAMCfGjduXMaNG5cxY8bE9Y3GIpwAoMF86UtfytatW3P88cfn0UcfzYUXXlj1JJ7nNU4A0GAefvjhXH/99UmSk046yY8ZaiCuOAFAg+nr68v27duTJDt27Mjg4GDFi3iBK04A0GA+8pGP5P3vf39mzJiR+++/P+ecc07Vk3ied9UBQAPq6enJ1q1bM3Xq1EyePLnqOTzPFScAaBDnn3/+S35t+fLl+3AJL0U4AUCDuPvuu7Njx47MnTs3b3nLWzyKoAG5VQcADWTz5s1Zt25d7rrrrhxzzDGZO3dupk2bVvUsniecAKBB3X777fne976Xxx9/PGvXrq16DnGrDgAaTm9vb37605/mxz/+cbZv3565c+dWPYnnueIEAA3ipptuyk033ZTf/e53ec973pNTTz01U6dOrXoWLyKcAKBBHHXUUTn88MNz1FFHJUlaWlqGvrZixYqqZvEibtUBQIP47ne/W/UE9sAVJwCAQn5WHQBAIeEEAFBIOAEAFBJOAACFhBMAQKH/BWihuLF3iAAJAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the new value counts for new essay score labels and plot them to a bar chart\n",
    "print(essays['EssayScore'].value_counts())\n",
    "essays['EssayScore'].value_counts().plot(kind='bar', figsize=(10,8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computers are better understanding the number, so the string class values for essay scores need to be encoded as numbers. In order to do that, a new python dictionary is created according to unique values of essay scores and this dictionary is used to replace the string score values as numerical score values. Then, column data type is converted to integer to ensure that the data is numerical and ready to be used in the machine learning model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f96ec1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Low Band': 0, 'Moderate Band': 1, 'High Band': 2}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a python dictionary to hold the unique values of target data. this dictionary will be used to encode the labels\n",
    "possible_labels = essays.EssayScore.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fa3e03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# encode the score data by using the label dictionary\n",
    "essays['EssayScore'] = essays.EssayScore.replace(label_dict)\n",
    "essays = essays.astype({'EssayScore': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.2 Named Entity Recognition\n",
    "Named entity recognition (NER) helps to easily identify the key elements in a text, like names of people, places, brands, monetary values, and more. Extracting the main entities in a text helps sort unstructured data and detect important information, which is crucial when it requires to deal with large datasets.\n",
    "\n",
    "Following two cells finds named entities in the essay text and replaces them with their corresponding NER labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# load spycy for named entity recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "\n",
    "# create the function for named entity recognition\n",
    "def ner_tag(text):\n",
    "    doc = nlp(text)\n",
    "    new_text = (\" \".join([t.text if not t.ent_type_ else '@' + t.ent_type_ for t in doc])).strip()\n",
    "    return new_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# apply named entity recognition to the essay text.\n",
    "essays['EssayBody'] = essays['EssayBody'].map(ner_tag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______\n",
    "______"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-Model Building\n",
    "### 3.1-Split Train-Test Data\n",
    "To be able to train the model, the dataset must be divided as train and test data set. The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model. It is a fast and easy procedure to perform, the results of which allow you to compare the performance of machine learning algorithms for the predictive modeling problem.\n",
    "\n",
    " Because in our dataset the labels are imbalanced, the dataset will be split in a stratified fashion, by using unique values of the target data. Thus, each label will have a balanced train and test data according to the proportion of the number of values. Below cell executes the code which splits the data into train and test data sets.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d77e0d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      EssayTopic  EssayBody  S1  S2  S3\nEssayScore data_type                                   \n0          train              19         19  19  19  19\n           val                 5          5   5   5   5\n1          train              17         17  17  17  17\n           val                 4          4   4   4   4\n2          train              18         18  18  18  18\n           val                 5          5   5   5   5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>EssayTopic</th>\n      <th>EssayBody</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n    </tr>\n    <tr>\n      <th>EssayScore</th>\n      <th>data_type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>19</td>\n      <td>19</td>\n      <td>19</td>\n      <td>19</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>18</td>\n      <td>18</td>\n      <td>18</td>\n      <td>18</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data to train-test dataset. Data will be split according to number of occurrences of each unique score.\n",
    "X_train, X_val, y_train, y_val = train_test_split(essays.index.values, \n",
    "                                                  essays.EssayScore.values, \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=essays.EssayScore.values)\n",
    "\n",
    "essays['data_type'] = ['not_set']*essays.shape[0]\n",
    "\n",
    "essays.loc[X_train, 'data_type'] = 'train'\n",
    "essays.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "# show the train-test dataset counts for each score value\n",
    "essays.groupby(['EssayScore', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2-Tokenize the Essay Text\n",
    "Tokenization is a way of separating a piece of text into smaller units called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.\n",
    "\n",
    "For our model, we will be implementing BERT tokenizer which uses what is called a WordPiece tokenizer. It works by splitting words either into the full forms (e.g., one word becomes one token) or into word pieces— where one word can be broken into multiple tokens.\n",
    "\n",
    "A pre-trained BERT model configuration must be initialized in order to encode the data. To convert all the essays from text into encoded form, a function called batch_encode_plus is used. Also train and validation data will be tokenized separately. Below code tokenizes all the data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ae9259",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# get the tokens for train data\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    essays[essays.data_type=='train'].EssayBody.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length = 318,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# get the tokens for test data\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    essays[essays.data_type=='val'].EssayBody.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length = 318,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# get input_ids, attention mask, and labels for train data\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(essays[essays.data_type=='train'].EssayScore.values)\n",
    "\n",
    "# get input_ids, attention mask, and labels for test data\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(essays[essays.data_type=='val'].EssayScore.values)\n",
    "\n",
    "# form train and test data from encoded data with tensors\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ba519",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After getting the tokenized data, it needs to be split into input_ids, attention_masks and labels. Input IDs are simply mappings between tokens and their respective IDs. The attention mask is to prevent the model from looking at padding tokens. Finally, encoded training dataset and test dataset is extracted from tokenized data. Now the data is ready to be used in the model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfa868",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3-Model Building\n",
    "#### 3.3.1 Model Selection\n",
    "For this project, data will be trained by using BERT - Bidirectional Encoder Representations from Transformers- which is a transformer-based machine learning technique for natural language processing (NLP) developed by Google. BERT was pre-trained on unsupervised Wikipedia and Bookcorpus datasets using language modeling.\n",
    "\n",
    "Two types of BERT models are introduced- BERTBase and BERTLarge – according to the depth of the model architecture. The BERTBase model uses 12 layers of transformers block with a hidden size of 768 and number of self-attention heads as 12 and has around 110M trainable parameters. On the other hand, BERTLarge uses 24 layers of transformers block with a hidden size of 1024 and number of self-attention heads as 16 and has around 340M trainable parameters.\n",
    "\n",
    "\n",
    "For the implementation of BERT for any task on our dataset, pre-trained weights are available and these pre-trained weights will be used to fine-tune the model on our own dataset. Each essay text is being treated as its unique sequence, so one sequence will be classified to one of the three labels (i.e. Low, moderate or high band). From the BERT model library, BertForSequenceClassification model is used with the following parameters\n",
    "•\tbert-base-uncased: as the pretrained weights which is a lightweight model.\n",
    "•\tUsing num_labels equal to length of label dictionary which indicates the number of output labels.\n",
    "•\toutput_attentions and output_hidden_states are set to false since they are not really required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b82340",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model selection: BERT sequence classifier model is used with pretrained weights.\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.2 Creating the Data Loaders\n",
    "PyTorch’s DataLoader is a useful feature that keeps the data organized and simplifies our machine learning pipeline. It allows us to iterate the data, manage batches, and shuffle the samples to avoid overfitting. In this project, we used RandomSampler for training and SequentialSampler for validation.\n",
    "\n",
    "The batch size refers to how many training instances are employed in a single iteration. This is usually used when the number of training instances is quite large, and it is usually effective to divide the entire data into small batches. Minimum number for batch size is 1. As the batch size increases, so the memory usage increases too. Thus, in case there is limited memory available, the batch size should be kept minimum.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c86a044f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the dataloaders with a batch size of 1\n",
    "batch_size = 1\n",
    "\n",
    "# create train dataloader with random sampler\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "# create validation dataloader with sequential sampler\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.3 Optimizer and Scheduler Selection\n",
    "For this project, Pytorch’s AdamW optimizer with a scheduler is used to optimize the learning process. The adam optimizer has several benefits such as it is straightforward to implement, has faster running time, low memory requirements, and requires less tuning than any other optimization algorithm.\n",
    "\n",
    "As the scheduler, get_linear_schedule_with_warmup from the transformers library is used to create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ddae58-6758-4e30-83d1-73a40b62f3fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# select AdamW optimizer for optimization job\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=3e-5, \n",
    "                  eps=1e-8)\n",
    "# set the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "# set the scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.4 Creating Accuracy Functions with Metrics\n",
    "For this project, F1 score has been used as a model performance metric. The F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all positive results, including those not identified correctly, and the recall is the number of true positive results divided by the number of all samples that should have been identified as positive.\n",
    "\n",
    "The F1 score becomes especially valuable when working on classification models in which the data set is imbalanced. Additionally, the F1 score works much better in estimating the performance of a machine learning model.\n",
    "\n",
    "Moreover, accuracy of each class is calculated by getting the number of true values and true predictions. This is done by the accuracy_per_class function. We will use this function after training and saving the model to see the accuracy of saved model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776beb30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this function calculates the F1 score\n",
    "def calculate_f1_score(predicted, labels):\n",
    "    predictions_flat = np.argmax(predicted, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, predictions_flat, average='weighted')\n",
    "\n",
    "# this function calculates the accuracy of each class by getting the correct predictions\n",
    "def accuracy_per_class(predicted, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    predictions_flat = np.argmax(predicted, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_predictions = predictions_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_predictions[y_predictions==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4a9ad62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# set the device to CUDA if GPU is available for fast processing, otherwise us CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.5 Evaluation Function\n",
    "Before starting to train the model, we will create the evaluation function which will perform predictions and validations for the model training and model evaluation. This functions includes an input parameter which holds the dataloader values for validation data. After execution, evaluation function returns three variables that keeps the results for average loss value, predicted values, and true values from test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1336670",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "    # switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # define variables to hold predictions, loss and true values\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    # Start predictions for each data in dataloader\n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    # calculate averge loss value\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "\n",
    "    # list predictions and true values\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    # return all the results\n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6520cb-8b37-4d70-98dd-1b9db95aa4a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function clears the cash in case there is not any available memory for cuda device\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.6 Model Training\n",
    "In the final step, we are ready to train our model by combining all the parameters created so far. Model is switched to training mode and fed by the training data which includes input ids, attention mask and the labels. A better visual representation is provided by adding the tqdm library and the progress bar. There are two loops; outer loop provides iterations for each epoch and inner loop provides iteration for training. At the end of each epoch, training loss, validation loss, and f1 score is calculated and the model is saved to a folder. The best model trained then will be used for evaluation purposes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a161b264",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db6ffb54ba44278848226cc7c70c8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.1003459416053913\n",
      "Validation loss: 1.0911068235124861\n",
      "F1 Score (Weighted): 0.3174603174603175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 1.0030735394469015\n",
      "Validation loss: 0.8250943379742759\n",
      "F1 Score (Weighted): 0.4693877551020408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.9710028397816198\n",
      "Validation loss: 0.6448051386645862\n",
      "F1 Score (Weighted): 0.8398268398268397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.7429846806658639\n",
      "Validation loss: 0.5844805517366954\n",
      "F1 Score (Weighted): 0.7736549165120594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.647342998534441\n",
      "Validation loss: 0.6297583042510918\n",
      "F1 Score (Weighted): 0.7142857142857144\n"
     ]
    }
   ],
   "source": [
    "# first loop to start iterate through each epoch\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    #switch model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "    #start training the model\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "    # save model for future use\n",
    "    torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    # calculate training loss\n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    # calculate validation loss and f1 score\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = calculate_f1_score(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.7 Accuracy Per Class\n",
    "After completing the training phase, the best model with the best f1 score is used for calculating the accuracy of each class. By using load_state_dict method of the model, first we load our saved model and then make predictions according to the test data. Finally, accuracy_per_class function was called to print the accuracy of each label value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c35e2a5-4812-45d4-aae7-ac472957a8f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Band-6\n",
      "Accuracy: 5/5\n",
      "\n",
      "Class: Band-7\n",
      "Accuracy: 2/4\n",
      "\n",
      "Class: Band-8\n",
      "Accuracy: 5/5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}